{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "PLANET_API_KEY = \"17de9ecc82734c1caf0ef0da1bf90d97\"\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = \"data/imgs/\"\n",
    "if not os.path.exists(outpath):\n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepath\n",
    "fp = \"shapes/boundary.shp\"\n",
    "# Read file using gpd.read_file()\n",
    "data = gpd.read_file(fp)\n",
    "#str(data.iloc[0]['geometry'])\n",
    "# check the data\n",
    "#gpd.GeoSeries([data.iloc[0]['geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms to geoseries and then to json\n",
    "a = json.loads(gpd.GeoSeries([data.iloc[0]['geometry']]).to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starts a session with planet api\n",
    "session = requests.Session()\n",
    "session.auth = (PLANET_API_KEY, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the desired geometry and saves it into a file for cropping later\n",
    "geojson_geometry = a['features'][0]['geometry']\n",
    "import json\n",
    "with open('subarea.geojson', 'w') as f:\n",
    "    json.dump(geojson_geometry, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images that overlap with our AOI\n",
    "geometry_filter = {\n",
    "    \"type\": \"GeometryFilter\",\n",
    "    \"field_name\": \"geometry\",\n",
    "    \"config\": geojson_geometry\n",
    "}\n",
    "\n",
    "# get images acquired within a date range\n",
    "date_range_filter = {\n",
    "    \"type\": \"DateRangeFilter\",\n",
    "    \"field_name\": \"acquired\",\n",
    "    \"config\": {\n",
    "        \"gte\": \"2021-04-01T00:00:00.000Z\",\n",
    "        \"lte\": \"2021-11-01T00:00:00.000Z\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# only get images which have <50% cloud coverage\n",
    "cloud_cover_filter = {\n",
    "    \"type\": \"RangeFilter\",\n",
    "    \"field_name\": \"cloud_cover\",\n",
    "    \"config\": {\n",
    "        \"lte\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# combine our geo, date, cloud filters\n",
    "combined_filter = {\n",
    "    \"type\": \"AndFilter\",\n",
    "    \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "}\n",
    "\n",
    "item_type = \"PSScene3Band\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# API request object\n",
    "search_request = {\n",
    "    \"name\": \"very_large_search\",\n",
    "    #\"interval\": \"week\",\n",
    "    \"item_types\": [item_type],\n",
    "    \"filter\": combined_filter\n",
    "}\n",
    "\n",
    "# fire off the POST request\n",
    "search_result = \\\n",
    "    requests.post(\n",
    "        'https://api.planet.com/data/v1/searches/',\n",
    "        auth=HTTPBasicAuth(PLANET_API_KEY, ''),\n",
    "        json=search_request)\n",
    "\n",
    "#print(json.dumps(search_result.json(), indent=1))\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_taken = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we want to do with each page of search results\n",
    "# in this case, just print out each id\n",
    "def handle_page(page):\n",
    "    for image in page[\"features\"]:\n",
    "        id0 = image['id'] \n",
    "        datet = parse(image['properties']['acquired'])\n",
    "        date_hash = f\"{datet.day}_{datet.month}_{datet.year}\"\n",
    "        if date_hash in dates_taken:\n",
    "            print(f\"{date_hash} already done\")\n",
    "            continue\n",
    "        dates_taken[date_hash] = 1\n",
    "        output_file =  outpath + str(id0) + '_subarea.tif'\n",
    "        output_file_xml =  outpath + str(id0) + '_subarea.xml'\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"exists {output_file}\")\n",
    "            #continue\n",
    "        image['filename'] = output_file\n",
    "        image['analytics_filename'] = output_file_xml\n",
    "\n",
    "        # For demo purposes, just grab the first image ID\n",
    "        id0_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(\n",
    "            item_type, id0)\n",
    "\n",
    "        # Returns JSON metadata for assets in this ID. Learn more: planet.com/docs/reference/data-api/items-assets/#asset\n",
    "        result = \\\n",
    "            requests.get(\n",
    "                id0_url,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "        # List of asset types available for this particular satellite image\n",
    "        #print(result.json().keys())\n",
    "        #print(result.json()['visual']['status'])\n",
    "\n",
    "        # Parse out useful links\n",
    "        links = result.json()[u\"visual\"][\"_links\"]\n",
    "        self_link = links[\"_self\"]\n",
    "        activation_link = links[\"activate\"]\n",
    "\n",
    "        # Request activation of the 'visual' asset:\n",
    "        activate_result = \\\n",
    "            requests.get(\n",
    "                activation_link,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "\n",
    "        activation_status_result = \\\n",
    "            requests.get(\n",
    "                self_link,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "        #print(activation_status_result.json()[\"status\"])\n",
    "        while activation_status_result.json()[\"status\"] != \"active\":\n",
    "            time.sleep(60)\n",
    "            activation_status_result = \\\n",
    "                requests.get(\n",
    "                    self_link,\n",
    "                    auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "                )\n",
    "            print(activation_status_result.json()[\"status\"])\n",
    "        # Image can be downloaded by making a GET with your Planet API key, from here:\n",
    "        #print(activation_status_result.json())\n",
    "        download_link = activation_status_result.json()[\"location\"]\n",
    "        #print(download_link)\n",
    "        vsicurl_url = '/vsicurl/' + download_link\n",
    "        # GDAL Warp crops the image by our AOI, and saves it\n",
    "        gdal.Warp(output_file, vsicurl_url, dstSRS = 'EPSG:4326', cutlineDSName = 'subarea.geojson', cropToCutline = True)\n",
    "\n",
    "        \n",
    "        \n",
    "        # band4\n",
    "        # For demo purposes, just grab the first image ID\n",
    "        id0_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(\n",
    "            \"PSScene4Band\", id0)\n",
    "\n",
    "        # Returns JSON metadata for assets in this ID. Learn more: planet.com/docs/reference/data-api/items-assets/#asset\n",
    "        result = \\\n",
    "            requests.get(\n",
    "                id0_url,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "        # List of asset types available for this particular satellite image\n",
    "        #print(result.json().keys())\n",
    "        #print(result.json()['visual']['status'])\n",
    "        #print(result.json())\n",
    "        # Parse out useful links\n",
    "        links = result.json()[u\"analytic_xml\"][\"_links\"]\n",
    "        self_link = links[\"_self\"]\n",
    "        activation_link = links[\"activate\"]\n",
    "\n",
    "        # Request activation of the 'visual' asset:\n",
    "        activate_result = \\\n",
    "            requests.get(\n",
    "                activation_link,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "\n",
    "        activation_status_result = \\\n",
    "            requests.get(\n",
    "                self_link,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "\n",
    "        #print(activation_status_result.json()[\"status\"])\n",
    "        while activation_status_result.json()[\"status\"] != \"active\":\n",
    "            activation_status_result = \\\n",
    "                requests.get(\n",
    "                    self_link,\n",
    "                    auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "                )\n",
    "            print(activation_status_result.json()[\"status\"])\n",
    "            time.sleep(60)\n",
    "        # Image can be downloaded by making a GET with your Planet API key, from here:\n",
    "        #print(activation_status_result.json())\n",
    "        download_link = activation_status_result.json()[\"location\"]\n",
    "        #print(download_link)\n",
    "        r = requests.get(download_link)\n",
    "        image['analytics_size'] = len(r.content)\n",
    "        open(output_file_xml, 'wb').write(r.content)\n",
    "\n",
    "\n",
    "        out_results.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists data/imgs/20211026_155333_69_106c_subarea.tif\n",
      "26_10_2021 already done\n",
      "exists data/imgs/20211020_164552_31_2406_subarea.tif\n",
      "20_10_2021 already done\n",
      "20_10_2021 already done\n",
      "exists data/imgs/20211018_164316_11_227a_subarea.tif\n",
      "exists data/imgs/20211017_164218_74_227c_subarea.tif\n",
      "17_10_2021 already done\n",
      "17_10_2021 already done\n",
      "exists data/imgs/20211016_160433_09_2262_subarea.tif\n",
      "16_10_2021 already done\n",
      "exists data/imgs/20211012_160613_84_2276_subarea.tif\n",
      "exists data/imgs/20211010_160429_68_2262_subarea.tif\n",
      "exists data/imgs/20211009_155515_80_2456_subarea.tif\n",
      "exists data/imgs/20211001_155520_0e26_subarea.tif\n",
      "1_10_2021 already done\n",
      "1_10_2021 already done\n",
      "exists data/imgs/20210929_155317_00_2449_subarea.tif\n",
      "29_9_2021 already done\n",
      "29_9_2021 already done\n",
      "exists data/imgs/20210928_164450_09_2413_subarea.tif\n",
      "28_9_2021 already done\n",
      "28_9_2021 already done\n",
      "exists data/imgs/20210927_164139_97_240f_subarea.tif\n",
      "27_9_2021 already done\n",
      "27_9_2021 already done\n",
      "27_9_2021 already done\n",
      "27_9_2021 already done\n",
      "exists data/imgs/20210926_171158_72_1061_subarea.tif\n",
      "26_9_2021 already done\n",
      "exists data/imgs/20210925_155544_67_2455_subarea.tif\n",
      "26_9_2021 already done\n",
      "25_9_2021 already done\n",
      "exists data/imgs/20210924_162250_0f22_subarea.tif\n",
      "24_9_2021 already done\n",
      "exists data/imgs/20210923_130251_1052_subarea.tif\n",
      "exists data/imgs/20210919_130016_0f21_subarea.tif\n",
      "exists data/imgs/20210918_160742_11_2233_subarea.tif\n",
      "exists data/imgs/20210916_162156_0f15_subarea.tif\n",
      "16_9_2021 already done\n",
      "16_9_2021 already done\n",
      "exists data/imgs/20210914_162537_0f4e_subarea.tif\n",
      "exists data/imgs/20210913_171335_70_1066_subarea.tif\n",
      "exists data/imgs/20210912_162047_1008_subarea.tif\n",
      "12_9_2021 already done\n",
      "12_9_2021 already done\n",
      "exists data/imgs/20210911_171154_70_105d_subarea.tif\n",
      "11_9_2021 already done\n",
      "exists data/imgs/20210910_155315_42_242a_subarea.tif\n",
      "exists data/imgs/20210909_164000_24_240a_subarea.tif\n",
      "9_9_2021 already done\n",
      "9_9_2021 already done\n",
      "exists data/imgs/20210907_164508_25_240f_subarea.tif\n",
      "7_9_2021 already done\n",
      "7_9_2021 already done\n",
      "7_9_2021 already done\n",
      "exists data/imgs/20210906_171244_70_1064_subarea.tif\n",
      "6_9_2021 already done\n",
      "6_9_2021 already done\n",
      "exists data/imgs/20210905_171139_67_1060_subarea.tif\n",
      "exists data/imgs/20210901_130435_1048_subarea.tif\n",
      "exists data/imgs/20210827_155517_48_2436_subarea.tif\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "active\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "active\n",
      "25_8_2021 already done\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "active\n",
      "activating\n",
      "active\n",
      "23_8_2021 already done\n",
      "23_8_2021 already done\n",
      "23_8_2021 already done\n",
      "exists data/imgs/20210822_164358_51_2407_subarea.tif\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "activating\n",
      "active\n",
      "22_8_2021 already done\n",
      "exists data/imgs/20210815_162211_101f_subarea.tif\n",
      "activating\n",
      "active\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-245dba64c70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# kick off the pagination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mfetch_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# extract image IDs only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-245dba64c70b>\u001b[0m in \u001b[0;36mfetch_page\u001b[0;34m(search_url)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnext_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_links\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnext_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfetch_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfirst_page\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-245dba64c70b>\u001b[0m in \u001b[0;36mfetch_page\u001b[0;34m(search_url)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnext_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_links\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnext_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfetch_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfirst_page\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-245dba64c70b>\u001b[0m in \u001b[0;36mfetch_page\u001b[0;34m(search_url)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhandle_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mnext_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_links\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnext_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7b62164de245>\u001b[0m in \u001b[0;36mhandle_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_status_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Image can be downloaded by making a GET with your Planet API key, from here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m#print(activation_status_result.json())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out_results = []\n",
    "\n",
    "# after you create a search, save the id. This is what is needed\n",
    "# to execute the search.\n",
    "search_result_id = search_result.json()[\"id\"]\n",
    "\n",
    "\n",
    "# How to Paginate:\n",
    "# 1) Request a page of search results\n",
    "# 2) do something with the page of results\n",
    "# 3) if there is more data, recurse and call this method on the next page.\n",
    "def fetch_page(search_url):\n",
    "    page = session.get(search_url).json()\n",
    "    handle_page(page)\n",
    "    next_url = page[\"_links\"].get(\"_next\")\n",
    "    if next_url:\n",
    "        fetch_page(next_url)\n",
    "\n",
    "first_page = \\\n",
    "    (\"https://api.planet.com/data/v1/searches/{}\" +\n",
    "        \"/results?_page_size={}\").format(search_result_id, 25)\n",
    "\n",
    "# kick off the pagination\n",
    "fetch_page(first_page)\n",
    "\n",
    "# extract image IDs only\n",
    "#image_ids = [feature['id'] for feature in search_result.json()['features']]\n",
    "#print(image_ids)\n",
    "#print(len(image_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from osgeo import gdal\n",
    "#results = search_result.json()\n",
    "#images = results['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the results into a nice list of dicts\n",
    "p_results = []\n",
    "for out in out_results:\n",
    "    p = {\n",
    "        'id': out['id'],\n",
    "        'filename': out['filename'],\n",
    "        'analytics_filename': out['analytics_filename'],\n",
    "        'analytics_size': out['analytics_size'],\n",
    "    }\n",
    "    p = dict(list(p.items()) + list(out['properties'].items()))\n",
    "    p['geometry']  = out['geometry']\n",
    "    p_results.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves results as a csv\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(p_results)\n",
    "df.to_csv('data/res.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_results = []\n",
    "for image in images[:10]:\n",
    "    id0 = image['id'] \n",
    "    output_file = 'data/' + str(id0) + '_subarea.tif'\n",
    "    image['filename'] = output_file\n",
    "    out_results.append(image)\n",
    "    # For demo purposes, just grab the first image ID\n",
    "    id0_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(\n",
    "        item_type, id0)\n",
    "\n",
    "    # Returns JSON metadata for assets in this ID. Learn more: planet.com/docs/reference/data-api/items-assets/#asset\n",
    "    result = \\\n",
    "        requests.get(\n",
    "            id0_url,\n",
    "            auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "        )\n",
    "\n",
    "    # List of asset types available for this particular satellite image\n",
    "    #print(result.json().keys())\n",
    "    #print(result.json()['visual']['status'])\n",
    "\n",
    "    # Parse out useful links\n",
    "    links = result.json()[u\"visual\"][\"_links\"]\n",
    "    self_link = links[\"_self\"]\n",
    "    activation_link = links[\"activate\"]\n",
    "\n",
    "    # Request activation of the 'visual' asset:\n",
    "    activate_result = \\\n",
    "        requests.get(\n",
    "            activation_link,\n",
    "            auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "        )\n",
    "\n",
    "\n",
    "    activation_status_result = \\\n",
    "        requests.get(\n",
    "            self_link,\n",
    "            auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "        )\n",
    "\n",
    "    #print(activation_status_result.json()[\"status\"])\n",
    "    while activation_status_result.json()[\"status\"] != \"active\":\n",
    "        time.sleep(20)\n",
    "        activation_status_result = \\\n",
    "            requests.get(\n",
    "                self_link,\n",
    "                auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "            )\n",
    "        print(activation_status_result.json()[\"status\"])\n",
    "    # Image can be downloaded by making a GET with your Planet API key, from here:\n",
    "    download_link = activation_status_result.json()[\"location\"]\n",
    "    #print(download_link)\n",
    "    vsicurl_url = '/vsicurl/' + download_link\n",
    "    # GDAL Warp crops the image by our AOI, and saves it\n",
    "    gdal.Warp(output_file, vsicurl_url, dstSRS = 'EPSG:4326', cutlineDSName = 'subarea.geojson', cropToCutline = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
